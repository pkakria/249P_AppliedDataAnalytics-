library(ISLR)

data(Default)

set.seed(1)

fit1 = glm(default~income + balance, data=Default, family=binomial)

summary(fit1)

set.seed(1)
train = sample(nrow(Default),nrow(Default)*0.5)

fit2 = glm(default~income+balance, data=Default, family=binomial, subset=train)

prob2 = predict(fit2,Default[-train,], type="response")
pred2 = ifelse(prob2 > 0.5, "Yes", "No")
table(pred2, Default[-train,]$default)

mean(Default[-train,]$default!= pred2) 

#test error is 0.0254

#repeat 1
set.seed(2)  
train = sample(nrow(Default), nrow(Default)*0.5)
fit2 = glm(default~income+balance, data=Default, family=binomial, subset=train)
prob2 = predict(fit2,Default[-train,],type="response")
pred2 = ifelse(prob2 > 0.5, "Yes", "No")
mean(Default[-train,]$default != pred2)

#repeat 2
train=sample(nrow(Default), nrow(Default)*0.5)
fit2=glm(default~income+balance, data=Default, family=binomial, subset=train)
prob2=predict(fit2, Default[-train,], type="response")
pred2=ifelse(prob2 > 0.5, "Yes", "No")
mean(Default[-train,]$default != pred2) 

train=sample(nrow(Default), nrow(Default)*0.5)
fit2=glm(default~income+balance, data=Default, family=binomial, subset=train)
prob2=predict(fit2, Default[-train,], type="response")
pred2=ifelse(prob2 > 0.5, "Yes", "No")
mean(Default[-train,]$default != pred2)

# from three repetitions, the test error is 2.5% consistance (0.02 appx)
#very less variance

set.seed(1)
train=sample(nrow(Default), nrow(Default)*0.5)
fit3=glm(default~income + balance + student, data=Default, family=binomial, subset=train)
prob3=predict(fit3, Default[-train,], type="response")
pred3=ifelse(prob3 > 0.5, "Yes", "No")
mean(Default[-train,]$default != pred3) 

#the test error is almost similar with adding "student". 
#there is no significance reduction in the error.

require(ISLR)
data(Default)
set.seed(1)
fit1=glm(default~income+balance, data=Default, family=binomial)
summary(fit1)

#estimated std error for income is 0.000004985 and for balance is 0.0002274

set.seed(1)
boot.fn=function(df, trainid) {
return(coef(glm(default~income + balance, data=df, family=binomial, subset=trainid)))
}
boot.fn(Default, 1:nrow(Default))

require(boot)
boot(Default,boot.fn,R=100)

#std error estimates are very close using glm and bootstrap 
#using R=100
#glm-(4.985e-06 for income,2.274e-04 for balance)
#bootstrap-(4.186088e-06 for income,2.226242e-04 for balance)

#n=100 (obvervations) 
#p=2 (features) 
#equation is-- 
# Y = X - 2X^2 + \epsilon

set.seed(1)
x=rnorm(100)  
y=x-2*x^2 + rnorm(100)

plot(x,y)

#relation b/w x and y is quadratic 

set.seed(1)
df = data.frame(y, x, x2=x^2, x3=x^3, x4=x^4) #df dataframe
fit1 = glm(y~x, data=df)
cv.err1 = cv.glm(df, fit1)
cv.err1$delta
fit2 = glm(y~x + x2, data=df)
cv.err2 = cv.glm(df, fit2)
cv.err2$delta
fit3 = glm(y~x + x2 + x3, data=df)
cv.err3 = cv.glm(df, fit3)
cv.err3$delta
fit4 = glm(y~x + x2 + x3 + x4, data=df)
cv.err4 = cv.glm(df, fit4)
cv.err4$delta

set.seed(2)
df = data.frame(y, x, x2=x^2, x3=x^3, x4=x^4)
fit1 = glm(y~x, data=df)
cv.err1 = cv.glm(df, fit1)
cv.err1$delta
fit2 = glm(y~x + x2, data=df)
cv.err2 = cv.glm(df, fit2)
cv.err2$delta
fit3 = glm(y~x + x2 + x3, data=df)
cv.err3 = cv.glm(df, fit3)
cv.err3$delta
fit4 = glm(y~x + x2 + x3 + x4, data=df)
cv.err4 = cv.glm(df, fit4)
cv.err4$delta

# no diff in results b/w (c) and (d)

#using quad model,x  x^2 x^3  having the least error. 
#it was expected as true model was generated by quadratic model

fitn = lm(y~poly(x,4))
summary(fitn)

#from summary, x and x^2 are the significant predictors.
#this agrees with cross-validation results  which indicates using
#x and x^2 gives the best outcome.
